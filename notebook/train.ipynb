{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa767200-3d0b-4966-a1c5-801ff7ecbe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/finetuning-model-qlora\n",
      "README.md     bash.sh    \u001b[0m\u001b[01;34mmodel_lora\u001b[0m/  requirements.txt  train.py\n",
      "\u001b[01;34m__pycache__\u001b[0m/  config.py  \u001b[01;34mnotebook\u001b[0m/    \u001b[01;34mresults\u001b[0m/          \u001b[01;34mwandb\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f12d07-a77d-4e38-a2d6-564690ecc8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7137251c-c27b-461f-8918-f10671b3bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# !git config --global credential.helper store\n",
    "login(token=os.environ.get(\"HF_TOKEN\"), add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868a1c24-551b-415e-944f-9c999e6b40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "from string import Template\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "# for traing set\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "# from langchain.prompts import PromptTemplate\n",
    "import matplotlib.pyplot as plt\n",
    "import bitsandbytes as bnb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# notebook specific\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9fe7a-e0ec-4d84-a2ca-bb2e2ea444ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbd2d10-642c-4556-9ebf-314b5cf403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataset_2_record(record):\n",
    "    input_value = record['input'] if record['input'] is not None else \"\"\n",
    "    context_value = record['context'] if record['context'] is not None else \"\"\n",
    "    \n",
    "    return {\n",
    "        'instruction': record['instruction'],\n",
    "        'context': input_value + context_value[:512],\n",
    "        'response': record['output'],\n",
    "        'category': None  \n",
    "    }\n",
    "\n",
    "def modify_dataset_3_record(record):\n",
    "    input_value = record['input'] if record['input'] is not None else \"\"\n",
    "    context_value = record['_context'] if '_context' in record and record['_context'] is not None else \"\"\n",
    "    combined_context = input_value + \" \" + context_value  \n",
    "\n",
    "    return {\n",
    "        'instruction': f\"(Quality: {record['quality_gain']}) + {record['instruction']}\",\n",
    "        'context': combined_context,\n",
    "        'response': record['output'],\n",
    "        'category': None \n",
    "    }\n",
    "\n",
    "def modify_dataset_4_record(record):\n",
    "    context_value = record['input'] + record['conversations'] if (record['input'] is not None and record['conversations'] is not None) else \"\"\n",
    "    instruction_value = record['prompt'] if record['prompt'] is not None else \"\"\n",
    "    response_value = record['completion'] if record['completion'] is not None else \"\"\n",
    "    \n",
    "    return {\n",
    "        'instruction': instruction_value,\n",
    "        'context': context_value,\n",
    "        'response': response_value,\n",
    "        'category': None \n",
    "    }\n",
    "\n",
    "def create_combined_text(record):\n",
    "    instruction_value = record['instruction'] if record['instruction'] is not None else \"\"\n",
    "    context_value = record['context'] if record['context'] is not None else \"\"\n",
    "    response_value = record['response'] if record['response'] is not None else \"\"\n",
    "    \n",
    "    # Wrapping the instruction with [INST] tokens\n",
    "    instruction_formatted = f\"<s> [INST] {instruction_value} [/INST]\"\n",
    "    \n",
    "    return {\n",
    "        'combined_text': instruction_formatted +\n",
    "                         '### context: ' + context_value[:1280] +\n",
    "                         '### response: ' + response_value +' </s>' \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a293a11-37dc-45cf-b22f-a63cbe69f0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60988f18-7edf-4756-ae27-ea88d142dcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8c34a-181c-4423-b749-11ea72844c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f79ca-492c-4aaf-bd30-c5ba64306c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34d89a-2e5f-4170-b7d6-238fd006b3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792864a9-7804-4d57-9956-1eb0d70ee267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5043a-192c-437e-a449-bf229b96ba82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdcdf1-9c96-48bb-bcc8-fdb6235ba015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5932ebf-bf19-4544-a84a-03cda982a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category'],\n",
       "        num_rows: 15011\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1 = load_dataset(\"lingjoor/databricks-dolly-15k-context-32k-rag\")\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac20520e-a7e8-4482-bc86-c1aecf55634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_2 =  load_dataset(\"lingjoor/longalpaca-12k-context-32k-rag\")\n",
    "# dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b41a3d0-c765-4cd8-a6e7-03a2c84d8041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'instruction', 'data_source', '_input', 'reward', 'ppl', 'len', '_context', 'naturalness', 'coherence', 'groundedness', 'understandability', 'seq_length', 'knn_1', 'knn_2', 'knn_3', 'knn_4', 'knn_5', 'knn_7', 'knn_8', 'knn_9', 'knn_10', 'expected_loss', 'row_id', 'quality_gain'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_3 =  load_dataset(\"lingjoor/platypus_with_quality_score\")\n",
    "dataset_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e13172-805b-4a77-9a46-306847723fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['conversations', 'source', 'prompt', 'completion', 'input', 'reward', 'len', 'knn_1', 'knn_2', 'knn_3', 'knn_4', 'knn_5', 'knn_6', 'knn_7', 'knn_8', 'knn_9', 'knn_10', 'expected_loss'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_4 =  load_dataset(\"lingjoor/lima_with_scores\")\n",
    "dataset_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4b8bc0-dd45-4df0-8653-30466c391b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_5 =  load_dataset(\"alexMTL/guanaco_q_a_dataset_1k\")\n",
    "dataset_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc0936-14c3-4b89-98b3-c43260ddcb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfecc1-b5ac-4966-abb0-43f3166b82d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366538c-ea44-4afb-b4f3-c7705a5bcff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8c508-9f52-419b-83cc-674c56b6d5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fce98e-f490-4041-92a7-ba1ccb23f22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b577dbb6-461f-481b-bdc2-087eadc53fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_2_modified = dataset_2['train'].map(modify_dataset_2_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b4541df-cb35-41a7-9d59-6baf938c5480",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3_modified = dataset_3['train'].map(modify_dataset_3_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5691c7-6532-4f60-8c0d-a14592994465",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_4_modified = dataset_4['train'].map(modify_dataset_4_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "401d7729-d3f7-47c7-adbe-2a0db3f5172c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'combined_text'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_5_modified = dataset_5['train'].map(lambda record: {'combined_text': record['text']})\n",
    "dataset_5_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1e117f-8547-47b1-af53-9f302a57b304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef5bcb-3b35-4f37-bdb5-aefb45f9aff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544186f8-72f8-438a-9cbc-550488c4d93b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638847f-c56f-4747-b1aa-897fa3cd95a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d545c35-9e10-4a1c-9f32-2e6464c94928",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dataset = concatenate_datasets([dataset_1['train'], dataset_3_modified, dataset_4_modified, dataset_5_modified])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9691142-c085-47f3-b5ed-73f2732bd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = concatenated_dataset.map(create_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bd9d38-377c-4bfe-a0b9-6824a5b86a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ad1da-5d20-414b-89ff-c3d8d764df03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7ab69-eecb-452f-8183-0cc85b1a6591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2a09b3-ad64-4c5a-9b4a-40e193c4618f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd2ced5-c881-48cf-be62-d4771079bda4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9b8a3-027a-4439-ad33-e8ad3e09ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36672a7-bf20-41d7-be52-3b83d2a0ab02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8ff638-edd5-4b4e-9406-28b96484b77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11ebf8-c7f2-40ed-b620-aaa14eace3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89314b7-bd3f-4d75-a363-bd50bb56f86d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbe3338a-a3a4-4675-beff-f9935478c166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b89cc7b29604ffbb36cffb0cb854a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# support llama base only\n",
    "\n",
    "model_name = config.model_name\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=config.use_4bit,\n",
    "    bnb_4bit_use_double_quant=config.use_nested_quant,\n",
    "    bnb_4bit_quant_type=config.bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtyp=config.bnb_4bit_compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "# this should be set as False for finetuning\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,  use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7fbcaf0-4d55-4b7f-a857-23dd51277a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd79df2f-be3c-47db-867c-42347f88ff7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA module names: ['gate_proj', 'o_proj', 'down_proj', 'up_proj', 'q_proj', 'v_proj', 'k_proj']\n"
     ]
    }
   ],
   "source": [
    "def find_linear_layers(model):\n",
    "    \"\"\" find linear layers in given transformer model \"\"\"\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        # 4 bits for qlora\n",
    "        if isinstance(module, bnb.nn.Linear4bit): \n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    print(f\"LoRA module names: {list(lora_module_names)}\")\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "target_modules = find_linear_layers(model)\n",
    "\n",
    "#for llama 2 (they need different target module)\n",
    "qlora_config = LoraConfig(\n",
    "            r=config.lora_r,\n",
    "            lora_alpha=config.lora_alpha,\n",
    "            target_modules=target_modules,\n",
    "            lora_dropout=config.lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bf758d2-4b0c-4bb8-8857-8d6736916183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnat-nitarach\u001b[0m (\u001b[33mlingjoor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/finetuning-model-qlora/wandb/run-20231021_130349-uoam9g6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora/runs/uoam9g6z' target=\"_blank\">jolly-puddle-1</a></strong> to <a href='https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora' target=\"_blank\">https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora/runs/uoam9g6z' target=\"_blank\">https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora/runs/uoam9g6z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lingjoor/1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora/runs/uoam9g6z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5ffc147ac0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"1-epoch-dolly-15k-context-32k-rag-platypus-lima-guanaco-neft-qlora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e01932-47ce-4c76-8f97-7ed1cda8d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"max_steps=1\" is just for testing execution\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    num_train_epochs=config.num_train_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    # gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    optim=config.optim,\n",
    "    # logging_steps=config.logging_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    fp16=config.fp16,\n",
    "    bf16=config.bf16,\n",
    "    max_grad_norm=config.max_grad_norm,\n",
    "    # max_steps=config.max_steps,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    group_by_length=config.group_by_length,\n",
    "    lr_scheduler_type=config.lr_scheduler_type,\n",
    "    save_total_limit=config.save_total_limit,\n",
    "    # evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    report_to=config.report_to,\n",
    "    # load_best_model_at_end=config.load_best_model_at_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "948b1f57-3185-42b4-8f08-37417ede1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7da4dcc7-cdc1-4c6e-a1ba-aabf171c1f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U git+https://github.com/huggingface/trl.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52ab6db4-714f-448d-8a57-e2d54196d51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:178: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef1f4e15680f4497b4854e41d14b3e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/41011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:221: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=final_dataset,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=qlora_config,\n",
    "    dataset_text_field='combined_text',  \n",
    "    max_seq_length=config.max_seq_length,\n",
    "    neftune_noise_alpha=config.neftune_noise_alpha,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea098f37-eba1-4771-a197-30494ff63884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='41011' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  336/41011 03:41 < 7:28:44, 1.51 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864636f-a7a7-4340-85c0-2df613c80358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd693bb-5e39-4384-b8ca-0e815f4fcc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9ff496-8099-4c2a-bdce-a0d55dbe5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "model_to_save.save_pretrained(config.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284acda2-0550-4ea0-b716-369f2fbff93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618361cb-94e7-4a92-828b-bd5969aa042f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908bf97-a075-4924-b4fc-1f492c3936ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60f498-a54f-4a42-8962-d2fb6bb82d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480fb02-393e-4924-ae06-ab62a0ba715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58b415-9ce5-4aa5-95dc-6fe280c8b617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6ce6a-b286-4ec6-ad70-9c69a1c0968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d337a-054c-4b24-9b06-c36270718871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f078a1a3-2255-4b0f-97f3-d5543f50ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cb04420-de0b-41c4-b050-363016d79a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora_config = LoraConfig.from_pretrained(config.save_dir)\n",
    "# model_lora = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e762a0db-d4c0-4466-bcce-166ee7ccd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List parameter names for both models\n",
    "# base_model_params = list(model.named_parameters())\n",
    "# lora_model_params = list(model_lora.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4d4e4a-b0b2-4de9-91cc-c098796ec972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dictionaries for easier access\n",
    "# base_model_dict = dict(base_model_params)\n",
    "# lora_model_dict = dict(lora_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "075569a7-43e0-498e-b6d3-7316d2e2f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in base_model_dict:\n",
    "#     if name in lora_model_dict:\n",
    "#         base_model_dict[name].data.copy_(lora_model_dict[name].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ccd9a-6c9f-4030-9c27-cd17722954fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9880fc-2b05-4ca8-8f99-b5fdea0715f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac76ce5-9659-4d48-9491-11f32405aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import prepare_model_for_int8_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37020c-dd85-4d6a-9d12-8e131fd04c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d20f2-4444-40c2-be0b-54018151231e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4744ca9b-b475-4509-98ff-a77d9ec0853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "# base_model = prepare_model_for_int8_training(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16be739b-8fcc-47b5-b017-a7acefbb2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_to_merge = model_lora.from_pretrained(AutoModelForCausalLM.from_pretrained(base_model).to(\"cuda\"), config.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6eaedbf-d45c-4142-8ae7-f55b5c87c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_model = model_to_merge.merge_and_unload()\n",
    "# merged_model.save_pretrained(merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8632107-30be-4818-a25f-c75ed84bdfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee6eefb-19ef-4a27-bb5a-3fbb5345ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "import transformers\n",
    "import os, time\n",
    "import tempfile\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import OPTForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b8594dd-34ce-46f8-a414-5386816fe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = model_name\n",
    "LORA_WEIGHTS = config.save_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ffe1f1f-62fe-4f48-b8b8-c0ed1d8910ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type opt. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93ad7a9a3214831863828b2553acf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForCausalLM were not initialized from the model checkpoint at teknium/CollectiveCognition-v1.1-Mistral-7B and are newly initialized: ['model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.final_layer_norm.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.31.final_layer_norm.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.embed_positions.weight', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.18.fc1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "    \n",
    "model = OPTForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\", \n",
    ")\n",
    "    \n",
    "model = PeftModel.from_pretrained(\n",
    "    model, \n",
    "    LORA_WEIGHTS, \n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\", \n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed0f6660-5d7d-40dc-8951-1ebba1b09989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"lingjoor/Mistral-7B-v1.1-Dolly-Longalpaca-Platypus-FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a047522-99ca-4069-80bf-7cfcafb8425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.save_pretrained(\"lingjoor/Mistral-7B-v1.1-Dolly-Longalpaca-Platypus-FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf546861-8088-4c21-b63b-99719def942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
