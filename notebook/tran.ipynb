{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa767200-3d0b-4966-a1c5-801ff7ecbe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/finetuning-model-qlora\n",
      "README.md     bash.sh    \u001b[0m\u001b[01;34mlingjoor\u001b[0m/    \u001b[01;34mnotebook\u001b[0m/         \u001b[01;34mresults\u001b[0m/  \u001b[01;34mwandb\u001b[0m/\n",
      "\u001b[01;34m__pycache__\u001b[0m/  config.py  \u001b[01;34mmodel_lora\u001b[0m/  requirements.txt  train.py\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8f12d07-a77d-4e38-a2d6-564690ecc8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7137251c-c27b-461f-8918-f10671b3bdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: write).\n",
      "Your token has been saved in your configured git credential helpers (store).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# !git config --global credential.helper store\n",
    "login(token=os.environ.get(\"HF_TOKEN\"), add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "868a1c24-551b-415e-944f-9c999e6b40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "from string import Template\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# for training\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import TrainingArguments, EarlyStoppingCallback\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "\n",
    "# for traing set\n",
    "from datasets import load_dataset, Dataset, concatenate_datasets\n",
    "# from langchain.prompts import PromptTemplate\n",
    "import matplotlib.pyplot as plt\n",
    "import bitsandbytes as bnb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# notebook specific\n",
    "from IPython.display import Markdown, display\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9fe7a-e0ec-4d84-a2ca-bb2e2ea444ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8e7450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbd2d10-642c-4556-9ebf-314b5cf403df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_dataset_2_record(record):\n",
    "    input_value = record['input'] if record['input'] is not None else \"\"\n",
    "    context_value = record['context'] if record['context'] is not None else \"\"\n",
    "    \n",
    "    return {\n",
    "        'instruction': record['instruction'],\n",
    "        'context': input_value + context_value[:512],\n",
    "        'response': record['output'],\n",
    "        'category': None  \n",
    "    }\n",
    "\n",
    "def modify_dataset_3_record(record):\n",
    "    input_value = record['input'] if record['input'] is not None else \"\"\n",
    "    context_value = record['_context'] if '_context' in record and record['_context'] is not None else \"\"\n",
    "    combined_context = input_value + \" \" + context_value  \n",
    "\n",
    "    return {\n",
    "        'instruction': record['instruction'],\n",
    "        'context': combined_context,\n",
    "        'response': record['output'],\n",
    "        'category': None \n",
    "    }\n",
    "\n",
    "def create_combined_text(record):\n",
    "    instruction_value = record['instruction'] if record['instruction'] is not None else \"\"\n",
    "    context_value = record['context'] if record['context'] is not None else \"\"\n",
    "    response_value = record['response'] if record['response'] is not None else \"\"\n",
    "    \n",
    "    # Wrapping the instruction with [INST] tokens\n",
    "    instruction_formatted = f\"[INST] {instruction_value} [/INST]\"\n",
    "    \n",
    "    return {\n",
    "        'combined_text': instruction_formatted +\n",
    "                         '### context: ' + context_value[:1280] +\n",
    "                         '### response: ' + response_value\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a293a11-37dc-45cf-b22f-a63cbe69f0a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60988f18-7edf-4756-ae27-ea88d142dcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b8c34a-181c-4423-b749-11ea72844c82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73f79ca-492c-4aaf-bd30-c5ba64306c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e34d89a-2e5f-4170-b7d6-238fd006b3fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792864a9-7804-4d57-9956-1eb0d70ee267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5043a-192c-437e-a449-bf229b96ba82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cdcdf1-9c96-48bb-bcc8-fdb6235ba015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5932ebf-bf19-4544-a84a-03cda982a21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7154c935bd5146f2874a3ba18992ee36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3953e6c9e81c4846abb204a67905bd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11bdd4eb2c104d8a8c261b4df952a455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/72.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557b972d56514b2182d5f371de05563b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43903d874ba142acb474c4faf47e6ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'context', 'response', 'category'],\n",
       "        num_rows: 15011\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1 = load_dataset(\"lingjoor/databricks-dolly-15k-context-32k-rag\")\n",
    "dataset_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac20520e-a7e8-4482-bc86-c1aecf55634a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebc8517ad2d46428b56a6a378a985fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/30.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c9e48e97f64651ba6c4972365aff9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2791c7aba90944cfb6d6ba1f2fcf3be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/606M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9af5f1f8a5e4c53b1e862c021135555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cada0d8a04c043b383eafd699c9e05e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'instruction', 'context', 'file', 'output'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_2 =  load_dataset(\"lingjoor/longalpaca-12k-context-32k-rag\")\n",
    "dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b41a3d0-c765-4cd8-a6e7-03a2c84d8041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e8e30a38fe49df80b10cfa6116f3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b3503da047402ba6e8b5168354d5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/65.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc65efa5b234260814ed33574afd3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d518646cacc4d55a4ea262765c18d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input', 'output', 'instruction', 'data_source', '_input', 'reward', 'ppl', 'len', '_context', 'naturalness', 'coherence', 'groundedness', 'understandability', 'seq_length', 'knn_1', 'knn_2', 'knn_3', 'knn_4', 'knn_5', 'knn_7', 'knn_8', 'knn_9', 'knn_10', 'expected_loss', 'row_id', 'quality_gain'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_3 =  load_dataset(\"lingjoor/platypus_with_quality_score\")\n",
    "dataset_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e13172-805b-4a77-9a46-306847723fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e2b99-2b75-4398-87f7-33cc90f6d448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b8bc0-dd45-4df0-8653-30466c391b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc0936-14c3-4b89-98b3-c43260ddcb90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bfecc1-b5ac-4966-abb0-43f3166b82d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7366538c-ea44-4afb-b4f3-c7705a5bcff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8c508-9f52-419b-83cc-674c56b6d5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fce98e-f490-4041-92a7-ba1ccb23f22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b577dbb6-461f-481b-bdc2-087eadc53fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaac722d44b64aba9ba1575dd0b3afb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_2_modified = dataset_2['train'].map(modify_dataset_2_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4541df-cb35-41a7-9d59-6baf938c5480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ea167c0f57462a987bbc1c374cc00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/24000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_3_modified = dataset_3['train'].map(modify_dataset_3_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d545c35-9e10-4a1c-9f32-2e6464c94928",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_dataset = concatenate_datasets([dataset_1['train'], dataset_2_modified, dataset_3_modified])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9691142-c085-47f3-b5ed-73f2732bd6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93309a19fbf4356a648b1d18a477828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/51011 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_dataset = concatenated_dataset.map(create_combined_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3338a-a3a4-4675-beff-f9935478c166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63205638e7844c1eae190e5d38992eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c3c03f5d314f18b1ca8fe20eca38a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)model.bin.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aced40d76d2842189426ee4dd29e1ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8232015359b4cb3a9815bbd09c818b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)l-00001-of-00002.bin:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# support llama base only\n",
    "\n",
    "model_name = config.model_name\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=config.use_4bit,\n",
    "    bnb_4bit_use_double_quant=config.use_nested_quant,\n",
    "    bnb_4bit_quant_type=config.bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtyp=config.bnb_4bit_compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "# this should be set as False for finetuning\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True,  use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fbcaf0-4d55-4b7f-a857-23dd51277a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79df2f-be3c-47db-867c-42347f88ff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_linear_layers(model):\n",
    "    \"\"\" find linear layers in given transformer model \"\"\"\n",
    "    lora_module_names = set()\n",
    "    for name, module in model.named_modules():\n",
    "        # 4 bits for qlora\n",
    "        if isinstance(module, bnb.nn.Linear4bit): \n",
    "            names = name.split('.')\n",
    "            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "\n",
    "    if 'lm_head' in lora_module_names:\n",
    "        lora_module_names.remove('lm_head')\n",
    "    print(f\"LoRA module names: {list(lora_module_names)}\")\n",
    "    return list(lora_module_names)\n",
    "\n",
    "\n",
    "target_modules = find_linear_layers(model)\n",
    "\n",
    "#for llama 2 (they need different target module)\n",
    "qlora_config = LoraConfig(\n",
    "            r=config.lora_r,\n",
    "            lora_alpha=config.lora_alpha,\n",
    "            target_modules=target_modules,\n",
    "            lora_dropout=config.lora_dropout,\n",
    "            bias=\"none\",\n",
    "            task_type=\"CAUSAL_LM\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf758d2-4b0c-4bb8-8857-8d6736916183",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnat-nitarach\u001b[0m (\u001b[33mlingjoor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/finetuning-model-qlora/wandb/run-20231020_234829-cswwqqjf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora/runs/cswwqqjf' target=\"_blank\">crimson-grass-3</a></strong> to <a href='https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora' target=\"_blank\">https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora/runs/cswwqqjf' target=\"_blank\">https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora/runs/cswwqqjf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/lingjoor/databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora/runs/cswwqqjf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2c0a635420>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"base-databricks-dolly-15k-longalpaca-12k-context-32k-rag-platypus_with_quality_score-qlora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5e01932-47ce-4c76-8f97-7ed1cda8d3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"max_steps=1\" is just for testing execution\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=config.output_dir,\n",
    "    num_train_epochs=config.num_train_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    optim=config.optim,\n",
    "    logging_steps=config.logging_steps,\n",
    "    learning_rate=config.learning_rate,\n",
    "    weight_decay=config.weight_decay,\n",
    "    fp16=config.fp16,\n",
    "    bf16=config.bf16,\n",
    "    max_grad_norm=config.max_grad_norm,\n",
    "    max_steps=config.max_steps,\n",
    "    warmup_ratio=config.warmup_ratio,\n",
    "    group_by_length=config.group_by_length,\n",
    "    lr_scheduler_type=config.lr_scheduler_type,\n",
    "    save_total_limit=config.save_total_limit,\n",
    "    # evaluation_strategy=\"no\",\n",
    "    save_strategy=\"steps\",\n",
    "    # report_to=config.report_to,\n",
    "    # load_best_model_at_end=config.load_best_model_at_end,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "948b1f57-3185-42b4-8f08-37417ede1c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb41fa2b-8186-4e5a-abae-873ff2de7f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category', 'input', 'file', 'output', 'data_source', '_input', 'reward', 'ppl', 'len', '_context', 'naturalness', 'coherence', 'groundedness', 'understandability', 'seq_length', 'knn_1', 'knn_2', 'knn_3', 'knn_4', 'knn_5', 'knn_7', 'knn_8', 'knn_9', 'knn_10', 'expected_loss', 'row_id', 'quality_gain', 'combined_text'],\n",
       "    num_rows: 51011\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ab6db4-714f-448d-8a57-e2d54196d51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:173: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/trl/trainer/sft_trainer.py:214: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=final_dataset,\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=qlora_config,\n",
    "    dataset_text_field='combined_text',  \n",
    "    max_seq_length=config.max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea098f37-eba1-4771-a197-30494ff63884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/usr/local/lib/python3.10/dist-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 01:13, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.838300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.464400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.044100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=15, training_loss=2.115580399831136, metrics={'train_runtime': 79.2178, 'train_samples_per_second': 0.947, 'train_steps_per_second': 0.189, 'total_flos': 3083354109394944.0, 'train_loss': 2.115580399831136, 'epoch': 0.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4864636f-a7a7-4340-85c0-2df613c80358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd693bb-5e39-4384-b8ca-0e815f4fcc6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce9ff496-8099-4c2a-bdce-a0d55dbe5703",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
    "model_to_save.save_pretrained(config.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284acda2-0550-4ea0-b716-369f2fbff93e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618361cb-94e7-4a92-828b-bd5969aa042f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908bf97-a075-4924-b4fc-1f492c3936ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60f498-a54f-4a42-8962-d2fb6bb82d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480fb02-393e-4924-ae06-ab62a0ba715a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c58b415-9ce5-4aa5-95dc-6fe280c8b617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6ce6a-b286-4ec6-ad70-9c69a1c0968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d337a-054c-4b24-9b06-c36270718871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f078a1a3-2255-4b0f-97f3-d5543f50ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cb04420-de0b-41c4-b050-363016d79a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lora_config = LoraConfig.from_pretrained(config.save_dir)\n",
    "# model_lora = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e762a0db-d4c0-4466-bcce-166ee7ccd647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # List parameter names for both models\n",
    "# base_model_params = list(model.named_parameters())\n",
    "# lora_model_params = list(model_lora.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4d4e4a-b0b2-4de9-91cc-c098796ec972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dictionaries for easier access\n",
    "# base_model_dict = dict(base_model_params)\n",
    "# lora_model_dict = dict(lora_model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "075569a7-43e0-498e-b6d3-7316d2e2f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name in base_model_dict:\n",
    "#     if name in lora_model_dict:\n",
    "#         base_model_dict[name].data.copy_(lora_model_dict[name].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ccd9a-6c9f-4030-9c27-cd17722954fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9880fc-2b05-4ca8-8f99-b5fdea0715f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac76ce5-9659-4d48-9491-11f32405aedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from peft import prepare_model_for_int8_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37020c-dd85-4d6a-9d12-8e131fd04c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4d20f2-4444-40c2-be0b-54018151231e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4744ca9b-b475-4509-98ff-a77d9ec0853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True, torch_dtype=torch.float16, device_map=\"auto\")\n",
    "# base_model = prepare_model_for_int8_training(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16be739b-8fcc-47b5-b017-a7acefbb2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_to_merge = model_lora.from_pretrained(AutoModelForCausalLM.from_pretrained(base_model).to(\"cuda\"), config.save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6eaedbf-d45c-4142-8ae7-f55b5c87c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_model = model_to_merge.merge_and_unload()\n",
    "# merged_model.save_pretrained(merged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8632107-30be-4818-a25f-c75ed84bdfcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ee6eefb-19ef-4a27-bb5a-3fbb5345ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "import transformers\n",
    "import os, time\n",
    "import tempfile\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import OPTForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b8594dd-34ce-46f8-a414-5386816fe658",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = model_name\n",
    "LORA_WEIGHTS = config.save_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ffe1f1f-62fe-4f48-b8b8-c0ed1d8910ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type mistral to instantiate a model of type opt. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f93ad7a9a3214831863828b2553acf91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of OPTForCausalLM were not initialized from the model checkpoint at teknium/CollectiveCognition-v1.1-Mistral-7B and are newly initialized: ['model.decoder.layers.2.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.bias', 'model.decoder.layers.19.self_attn_layer_norm.weight', 'model.decoder.layers.19.fc1.weight', 'model.decoder.layers.15.self_attn.v_proj.weight', 'model.decoder.layers.16.final_layer_norm.bias', 'model.decoder.layers.26.fc1.weight', 'model.decoder.layers.11.self_attn_layer_norm.weight', 'model.decoder.layers.20.fc1.weight', 'model.decoder.layers.27.self_attn_layer_norm.weight', 'model.decoder.layers.19.final_layer_norm.weight', 'model.decoder.layers.17.fc2.weight', 'model.decoder.layers.22.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.bias', 'model.decoder.layers.1.final_layer_norm.bias', 'model.decoder.layers.27.self_attn.q_proj.bias', 'model.decoder.layers.15.self_attn.q_proj.weight', 'model.decoder.layers.10.self_attn.q_proj.weight', 'model.decoder.layers.12.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.weight', 'model.decoder.layers.14.self_attn.k_proj.bias', 'model.decoder.layers.31.fc2.bias', 'model.decoder.layers.7.fc2.weight', 'model.decoder.layers.20.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.k_proj.weight', 'model.decoder.layers.25.self_attn.v_proj.weight', 'model.decoder.layers.27.self_attn.out_proj.bias', 'model.decoder.layers.5.fc1.weight', 'model.decoder.layers.22.fc1.weight', 'model.decoder.layers.17.self_attn.q_proj.weight', 'model.decoder.layers.4.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.weight', 'model.decoder.layers.26.final_layer_norm.bias', 'model.decoder.layers.10.self_attn.out_proj.bias', 'model.decoder.layers.29.final_layer_norm.weight', 'model.decoder.layers.15.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.q_proj.weight', 'model.decoder.layers.29.fc2.weight', 'model.decoder.layers.16.self_attn.v_proj.bias', 'model.decoder.layers.24.self_attn.v_proj.weight', 'model.decoder.layers.4.self_attn_layer_norm.bias', 'model.decoder.layers.6.self_attn.v_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.bias', 'model.decoder.layers.5.self_attn.v_proj.bias', 'model.decoder.layers.5.final_layer_norm.weight', 'model.decoder.layers.11.final_layer_norm.bias', 'model.decoder.layers.12.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn.q_proj.bias', 'model.decoder.layers.27.self_attn_layer_norm.bias', 'model.decoder.layers.7.self_attn.out_proj.weight', 'model.decoder.layers.0.self_attn.v_proj.weight', 'model.decoder.layers.15.self_attn.v_proj.bias', 'model.decoder.layers.14.self_attn.out_proj.weight', 'model.decoder.layers.18.self_attn.out_proj.bias', 'model.decoder.layers.10.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.v_proj.weight', 'model.decoder.layers.5.fc2.weight', 'model.decoder.layers.7.fc1.weight', 'model.decoder.layers.19.final_layer_norm.bias', 'model.decoder.layers.22.self_attn_layer_norm.bias', 'model.decoder.layers.27.fc1.bias', 'model.decoder.layers.10.fc1.weight', 'model.decoder.layers.12.fc2.weight', 'model.decoder.layers.2.fc2.weight', 'model.decoder.layers.11.self_attn.out_proj.bias', 'model.decoder.layers.27.fc1.weight', 'model.decoder.layers.0.fc1.weight', 'model.decoder.layers.9.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn_layer_norm.bias', 'model.decoder.layers.16.fc2.bias', 'model.decoder.layers.26.fc2.weight', 'model.decoder.layers.24.self_attn_layer_norm.weight', 'model.decoder.layers.17.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.q_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.q_proj.weight', 'model.decoder.layers.31.self_attn.q_proj.weight', 'model.decoder.layers.24.fc2.bias', 'model.decoder.layers.8.final_layer_norm.weight', 'model.decoder.layers.12.self_attn.q_proj.bias', 'model.decoder.layers.10.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.out_proj.weight', 'model.decoder.layers.0.fc2.bias', 'model.decoder.layers.20.self_attn.k_proj.bias', 'model.decoder.layers.4.self_attn.v_proj.weight', 'model.decoder.layers.15.fc1.bias', 'model.decoder.layers.13.final_layer_norm.bias', 'model.decoder.layers.1.self_attn.k_proj.weight', 'model.decoder.layers.15.fc2.bias', 'model.decoder.layers.20.self_attn.v_proj.bias', 'model.decoder.layers.3.final_layer_norm.weight', 'model.decoder.layers.23.self_attn.k_proj.bias', 'model.decoder.layers.6.final_layer_norm.weight', 'model.decoder.layers.13.self_attn_layer_norm.weight', 'model.decoder.layers.6.fc2.weight', 'model.decoder.layers.20.fc2.weight', 'model.decoder.layers.2.self_attn.out_proj.weight', 'model.decoder.layers.10.self_attn_layer_norm.bias', 'model.decoder.layers.15.final_layer_norm.bias', 'model.decoder.layers.31.fc1.bias', 'model.decoder.layers.25.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.bias', 'model.decoder.layers.24.fc2.weight', 'model.decoder.layers.17.fc2.bias', 'model.decoder.layers.1.fc2.bias', 'model.decoder.layers.29.self_attn.k_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.bias', 'model.decoder.layers.7.final_layer_norm.weight', 'model.decoder.layers.30.fc2.weight', 'model.decoder.layers.30.self_attn.v_proj.weight', 'model.decoder.layers.18.self_attn.q_proj.weight', 'model.decoder.layers.0.fc1.bias', 'model.decoder.layers.10.self_attn_layer_norm.weight', 'model.decoder.layers.1.fc2.weight', 'model.decoder.layers.12.fc1.bias', 'model.decoder.layers.13.fc1.bias', 'model.decoder.layers.14.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.q_proj.bias', 'model.decoder.layers.11.fc2.bias', 'model.decoder.layers.12.self_attn.k_proj.bias', 'model.decoder.layers.14.self_attn.v_proj.bias', 'model.decoder.layers.4.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.bias', 'model.decoder.layers.6.self_attn_layer_norm.weight', 'model.decoder.layers.11.self_attn_layer_norm.bias', 'model.decoder.layers.24.self_attn.out_proj.weight', 'model.decoder.layers.27.fc2.bias', 'model.decoder.layers.9.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.k_proj.bias', 'model.decoder.layers.6.fc1.bias', 'model.decoder.layers.6.fc2.bias', 'model.decoder.layers.26.self_attn.out_proj.weight', 'model.decoder.layers.6.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.q_proj.weight', 'model.decoder.layers.0.final_layer_norm.bias', 'model.decoder.layers.13.final_layer_norm.weight', 'model.decoder.layers.22.self_attn.v_proj.bias', 'model.decoder.layers.6.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn_layer_norm.bias', 'model.decoder.layers.12.self_attn.v_proj.bias', 'model.decoder.layers.8.fc2.bias', 'model.decoder.layers.31.self_attn.out_proj.bias', 'model.decoder.layers.25.self_attn.out_proj.bias', 'model.decoder.layers.5.self_attn.q_proj.weight', 'model.decoder.layers.10.fc2.weight', 'model.decoder.layers.8.self_attn_layer_norm.bias', 'model.decoder.layers.12.self_attn_layer_norm.weight', 'model.decoder.layers.29.fc2.bias', 'model.decoder.layers.31.self_attn_layer_norm.weight', 'model.decoder.layers.13.fc2.bias', 'model.decoder.layers.2.final_layer_norm.bias', 'model.decoder.layers.2.self_attn_layer_norm.bias', 'model.decoder.layers.5.self_attn.k_proj.weight', 'model.decoder.layers.24.self_attn.k_proj.bias', 'model.decoder.layers.24.final_layer_norm.bias', 'model.decoder.layers.25.fc2.bias', 'model.decoder.layers.29.self_attn.out_proj.bias', 'model.decoder.layers.30.self_attn.k_proj.bias', 'model.decoder.layers.31.self_attn_layer_norm.bias', 'model.decoder.layers.29.self_attn.out_proj.weight', 'model.decoder.layers.23.fc2.bias', 'model.decoder.layers.14.self_attn.out_proj.bias', 'model.decoder.layers.6.self_attn.q_proj.weight', 'model.decoder.layers.20.self_attn.out_proj.weight', 'model.decoder.layers.23.self_attn.k_proj.weight', 'model.decoder.layers.29.fc1.weight', 'model.decoder.layers.19.self_attn.v_proj.weight', 'model.decoder.layers.2.self_attn_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn.v_proj.bias', 'model.decoder.layers.25.final_layer_norm.bias', 'model.decoder.layers.4.fc2.bias', 'model.decoder.layers.25.self_attn.k_proj.weight', 'model.decoder.layers.24.fc1.bias', 'model.decoder.layers.20.fc2.bias', 'model.decoder.layers.7.final_layer_norm.bias', 'model.decoder.final_layer_norm.weight', 'model.decoder.layers.22.fc1.bias', 'model.decoder.layers.2.self_attn.q_proj.bias', 'model.decoder.layers.20.self_attn_layer_norm.weight', 'model.decoder.layers.23.final_layer_norm.bias', 'model.decoder.layers.20.self_attn_layer_norm.bias', 'model.decoder.layers.21.self_attn.out_proj.weight', 'model.decoder.layers.28.fc2.weight', 'model.decoder.layers.31.self_attn.v_proj.bias', 'model.decoder.layers.10.self_attn.v_proj.bias', 'model.decoder.layers.13.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.out_proj.bias', 'model.decoder.layers.7.fc2.bias', 'model.decoder.layers.0.final_layer_norm.weight', 'model.decoder.layers.10.self_attn.k_proj.weight', 'model.decoder.layers.30.self_attn.out_proj.weight', 'model.decoder.layers.1.fc1.bias', 'model.decoder.layers.18.fc2.bias', 'model.decoder.layers.16.self_attn.k_proj.weight', 'model.decoder.layers.8.fc2.weight', 'model.decoder.layers.28.self_attn.v_proj.weight', 'model.decoder.layers.9.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.k_proj.weight', 'model.decoder.layers.31.fc2.weight', 'model.decoder.layers.16.self_attn.out_proj.weight', 'model.decoder.layers.16.self_attn.out_proj.bias', 'model.decoder.layers.27.self_attn.k_proj.bias', 'model.decoder.layers.16.fc1.weight', 'model.decoder.layers.12.fc1.weight', 'model.decoder.layers.26.self_attn_layer_norm.bias', 'model.decoder.layers.24.self_attn.q_proj.weight', 'model.decoder.layers.17.fc1.bias', 'model.decoder.layers.22.self_attn.k_proj.bias', 'model.decoder.layers.17.self_attn.v_proj.bias', 'model.decoder.layers.7.self_attn.out_proj.bias', 'model.decoder.layers.26.fc2.bias', 'model.decoder.layers.14.self_attn.q_proj.bias', 'model.decoder.layers.31.self_attn.v_proj.weight', 'model.decoder.layers.21.fc2.weight', 'model.decoder.layers.8.self_attn.v_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.bias', 'model.decoder.layers.26.self_attn.k_proj.weight', 'model.decoder.layers.16.fc1.bias', 'model.decoder.layers.22.self_attn_layer_norm.weight', 'model.decoder.layers.13.self_attn.v_proj.weight', 'model.decoder.layers.14.self_attn_layer_norm.weight', 'model.decoder.layers.21.self_attn.q_proj.weight', 'model.decoder.layers.21.final_layer_norm.weight', 'model.decoder.layers.30.self_attn.q_proj.bias', 'model.decoder.layers.9.self_attn.k_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn_layer_norm.bias', 'model.decoder.layers.26.self_attn.v_proj.weight', 'model.decoder.layers.26.self_attn.k_proj.bias', 'model.decoder.layers.27.fc2.weight', 'model.decoder.layers.8.fc1.bias', 'model.decoder.layers.14.self_attn.k_proj.weight', 'model.decoder.layers.8.self_attn.q_proj.weight', 'model.decoder.layers.28.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.k_proj.bias', 'model.decoder.layers.10.self_attn.k_proj.bias', 'model.decoder.layers.14.final_layer_norm.bias', 'model.decoder.layers.1.fc1.weight', 'model.decoder.layers.9.final_layer_norm.weight', 'model.decoder.layers.17.self_attn.q_proj.bias', 'model.decoder.layers.22.self_attn.q_proj.bias', 'model.decoder.layers.26.final_layer_norm.weight', 'model.decoder.layers.16.self_attn_layer_norm.bias', 'model.decoder.layers.21.fc2.bias', 'model.decoder.layers.6.self_attn.v_proj.weight', 'model.decoder.layers.13.self_attn.q_proj.bias', 'model.decoder.layers.20.fc1.bias', 'model.decoder.layers.13.fc1.weight', 'model.decoder.layers.2.final_layer_norm.weight', 'model.decoder.layers.21.self_attn_layer_norm.weight', 'model.decoder.layers.3.self_attn.out_proj.bias', 'model.decoder.layers.31.fc1.weight', 'model.decoder.layers.17.self_attn.out_proj.weight', 'model.decoder.layers.1.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.weight', 'model.decoder.layers.31.final_layer_norm.weight', 'model.decoder.layers.0.self_attn.v_proj.bias', 'model.decoder.layers.9.fc1.weight', 'model.decoder.layers.1.self_attn.out_proj.weight', 'model.decoder.layers.19.self_attn.out_proj.bias', 'model.decoder.layers.17.self_attn_layer_norm.bias', 'model.decoder.layers.30.fc1.bias', 'model.decoder.layers.9.self_attn.out_proj.weight', 'model.decoder.layers.2.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn.v_proj.bias', 'model.decoder.layers.15.fc2.weight', 'model.decoder.layers.9.self_attn.out_proj.bias', 'model.decoder.layers.16.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.weight', 'model.decoder.layers.24.final_layer_norm.weight', 'model.decoder.layers.28.final_layer_norm.weight', 'model.decoder.layers.25.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc2.weight', 'model.decoder.layers.20.final_layer_norm.weight', 'model.decoder.layers.15.self_attn_layer_norm.weight', 'model.decoder.layers.18.final_layer_norm.weight', 'model.decoder.layers.25.self_attn.out_proj.weight', 'model.decoder.layers.26.self_attn_layer_norm.weight', 'model.decoder.layers.0.self_attn.q_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.weight', 'model.decoder.layers.4.final_layer_norm.weight', 'model.decoder.layers.27.self_attn.out_proj.weight', 'model.decoder.layers.14.final_layer_norm.weight', 'model.decoder.layers.16.self_attn.v_proj.weight', 'model.decoder.layers.23.fc2.weight', 'model.decoder.layers.22.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.k_proj.weight', 'model.decoder.layers.27.self_attn.v_proj.bias', 'model.decoder.layers.12.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn.k_proj.weight', 'model.decoder.layers.18.self_attn.k_proj.weight', 'model.decoder.layers.7.self_attn.q_proj.bias', 'model.decoder.layers.27.final_layer_norm.bias', 'model.decoder.layers.25.fc1.bias', 'model.decoder.layers.15.self_attn.k_proj.bias', 'model.decoder.layers.29.fc1.bias', 'model.decoder.layers.21.fc1.bias', 'model.decoder.layers.25.self_attn_layer_norm.weight', 'model.decoder.layers.9.fc2.bias', 'model.decoder.layers.23.self_attn.q_proj.bias', 'model.decoder.layers.25.fc1.weight', 'model.decoder.layers.2.fc1.bias', 'model.decoder.layers.2.self_attn.q_proj.weight', 'model.decoder.layers.12.fc2.bias', 'model.decoder.layers.0.self_attn.out_proj.bias', 'model.decoder.layers.18.final_layer_norm.bias', 'model.decoder.layers.20.self_attn.out_proj.bias', 'model.decoder.layers.17.fc1.weight', 'model.decoder.layers.4.self_attn.out_proj.bias', 'model.decoder.layers.31.final_layer_norm.bias', 'model.decoder.layers.0.fc2.weight', 'model.decoder.layers.13.self_attn.out_proj.bias', 'model.decoder.layers.14.fc1.bias', 'model.decoder.layers.22.fc2.bias', 'model.decoder.layers.14.fc2.bias', 'model.decoder.layers.18.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.v_proj.bias', 'model.decoder.layers.12.final_layer_norm.bias', 'model.decoder.layers.25.fc2.weight', 'model.decoder.layers.9.self_attn_layer_norm.weight', 'model.decoder.layers.2.self_attn.k_proj.bias', 'model.decoder.layers.26.self_attn.q_proj.bias', 'model.decoder.layers.16.final_layer_norm.weight', 'model.decoder.layers.25.final_layer_norm.weight', 'model.decoder.layers.0.self_attn_layer_norm.bias', 'model.decoder.layers.4.self_attn_layer_norm.weight', 'model.decoder.layers.12.self_attn.out_proj.weight', 'model.decoder.layers.21.final_layer_norm.bias', 'model.decoder.layers.28.self_attn.q_proj.bias', 'model.decoder.layers.0.self_attn.out_proj.weight', 'model.decoder.layers.14.self_attn.q_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.bias', 'model.decoder.layers.22.self_attn.out_proj.bias', 'model.decoder.layers.3.fc1.bias', 'model.decoder.layers.28.fc1.weight', 'model.decoder.layers.24.self_attn.q_proj.bias', 'model.decoder.layers.15.final_layer_norm.weight', 'model.decoder.embed_positions.weight', 'model.decoder.layers.28.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn_layer_norm.bias', 'model.decoder.layers.25.self_attn.v_proj.bias', 'model.decoder.layers.2.fc1.weight', 'model.decoder.layers.30.self_attn.v_proj.bias', 'model.decoder.layers.23.self_attn_layer_norm.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.layers.22.self_attn.q_proj.weight', 'model.decoder.layers.28.final_layer_norm.bias', 'model.decoder.layers.24.self_attn.k_proj.weight', 'model.decoder.layers.2.fc2.bias', 'model.decoder.layers.19.fc1.bias', 'model.decoder.layers.3.fc2.weight', 'model.decoder.layers.8.fc1.weight', 'model.decoder.layers.9.final_layer_norm.bias', 'model.decoder.layers.21.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.v_proj.weight', 'model.decoder.layers.18.fc1.bias', 'model.decoder.layers.21.fc1.weight', 'model.decoder.layers.13.self_attn.k_proj.bias', 'model.decoder.layers.13.self_attn.v_proj.bias', 'model.decoder.layers.29.self_attn.q_proj.bias', 'model.decoder.layers.29.self_attn_layer_norm.weight', 'model.decoder.layers.9.self_attn.v_proj.bias', 'model.decoder.layers.30.fc1.weight', 'model.decoder.layers.19.self_attn.q_proj.weight', 'model.decoder.layers.18.self_attn.v_proj.weight', 'model.decoder.layers.4.fc1.bias', 'model.decoder.layers.9.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn_layer_norm.bias', 'model.decoder.layers.2.self_attn.v_proj.bias', 'model.decoder.layers.30.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn.k_proj.bias', 'model.decoder.layers.18.self_attn_layer_norm.weight', 'model.decoder.layers.1.self_attn.k_proj.bias', 'model.decoder.layers.29.final_layer_norm.bias', 'model.decoder.layers.17.self_attn.out_proj.bias', 'model.decoder.layers.23.fc1.weight', 'model.decoder.layers.5.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.out_proj.bias', 'model.decoder.layers.19.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.bias', 'model.decoder.layers.3.self_attn.k_proj.bias', 'model.decoder.layers.3.self_attn.v_proj.bias', 'model.decoder.layers.21.self_attn_layer_norm.bias', 'model.decoder.layers.9.fc1.bias', 'model.decoder.layers.1.self_attn_layer_norm.bias', 'model.decoder.layers.4.fc2.weight', 'model.decoder.layers.10.self_attn.v_proj.weight', 'model.decoder.layers.30.self_attn.k_proj.weight', 'model.decoder.layers.11.self_attn.k_proj.weight', 'model.decoder.layers.3.self_attn.q_proj.weight', 'model.decoder.layers.22.self_attn.k_proj.weight', 'model.decoder.layers.23.self_attn.v_proj.bias', 'model.decoder.layers.24.fc1.weight', 'model.decoder.layers.3.self_attn_layer_norm.weight', 'model.decoder.layers.15.self_attn.out_proj.weight', 'model.decoder.layers.13.self_attn.k_proj.weight', 'model.decoder.layers.29.self_attn.v_proj.weight', 'model.decoder.layers.11.self_attn.q_proj.weight', 'model.decoder.layers.13.fc2.weight', 'model.decoder.layers.3.self_attn.out_proj.weight', 'model.decoder.layers.3.self_attn.k_proj.weight', 'model.decoder.layers.19.self_attn.q_proj.bias', 'model.decoder.layers.6.self_attn.out_proj.bias', 'model.decoder.layers.30.final_layer_norm.weight', 'model.decoder.layers.25.self_attn.q_proj.weight', 'model.decoder.layers.19.self_attn.k_proj.weight', 'model.decoder.layers.28.self_attn.out_proj.weight', 'model.decoder.layers.30.fc2.bias', 'model.decoder.layers.7.self_attn_layer_norm.bias', 'model.decoder.layers.8.self_attn.out_proj.weight', 'model.decoder.layers.28.fc2.bias', 'model.decoder.layers.27.self_attn.k_proj.weight', 'model.decoder.layers.28.fc1.bias', 'model.decoder.layers.6.fc1.weight', 'model.decoder.layers.25.self_attn.q_proj.bias', 'model.decoder.layers.30.self_attn_layer_norm.bias', 'model.decoder.layers.3.fc2.bias', 'model.decoder.layers.28.self_attn.q_proj.weight', 'model.decoder.layers.6.self_attn.k_proj.bias', 'model.decoder.layers.24.self_attn.out_proj.bias', 'model.decoder.layers.11.self_attn.q_proj.bias', 'model.decoder.layers.23.self_attn.out_proj.weight', 'model.decoder.layers.7.self_attn.k_proj.weight', 'model.decoder.layers.16.fc2.weight', 'model.decoder.layers.18.fc2.weight', 'model.decoder.layers.5.self_attn_layer_norm.weight', 'model.decoder.layers.17.final_layer_norm.weight', 'model.decoder.layers.22.fc2.weight', 'model.decoder.layers.22.final_layer_norm.bias', 'model.decoder.layers.5.self_attn.out_proj.weight', 'model.decoder.layers.28.self_attn.k_proj.bias', 'model.decoder.layers.5.final_layer_norm.bias', 'model.decoder.layers.20.final_layer_norm.bias', 'model.decoder.layers.26.self_attn.v_proj.bias', 'model.decoder.layers.30.final_layer_norm.bias', 'model.decoder.layers.28.self_attn_layer_norm.weight', 'model.decoder.layers.7.self_attn.q_proj.weight', 'model.decoder.layers.1.self_attn.v_proj.weight', 'model.decoder.layers.5.self_attn.k_proj.bias', 'model.decoder.layers.16.self_attn_layer_norm.weight', 'model.decoder.layers.19.fc2.bias', 'model.decoder.layers.24.self_attn.v_proj.bias', 'model.decoder.layers.28.self_attn.out_proj.bias', 'model.decoder.layers.2.self_attn.out_proj.bias', 'model.decoder.layers.27.final_layer_norm.weight', 'model.decoder.layers.4.self_attn.q_proj.weight', 'model.decoder.layers.17.self_attn_layer_norm.weight', 'model.decoder.layers.23.self_attn_layer_norm.bias', 'model.decoder.layers.0.self_attn_layer_norm.weight', 'model.decoder.layers.5.self_attn.v_proj.weight', 'model.decoder.layers.23.fc1.bias', 'model.decoder.layers.3.fc1.weight', 'model.decoder.layers.8.final_layer_norm.bias', 'model.decoder.layers.11.self_attn.out_proj.weight', 'model.decoder.layers.5.self_attn.out_proj.bias', 'model.decoder.layers.31.self_attn.out_proj.weight', 'model.decoder.layers.27.self_attn.q_proj.weight', 'model.decoder.layers.10.fc2.bias', 'model.decoder.layers.12.self_attn.v_proj.weight', 'model.decoder.layers.10.final_layer_norm.bias', 'model.decoder.layers.3.self_attn_layer_norm.bias', 'model.decoder.layers.26.fc1.bias', 'model.decoder.layers.1.self_attn_layer_norm.weight', 'model.decoder.layers.6.final_layer_norm.bias', 'model.decoder.layers.18.self_attn.k_proj.bias', 'model.decoder.layers.27.self_attn.v_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.bias', 'model.decoder.layers.7.self_attn.v_proj.bias', 'model.decoder.layers.11.self_attn.v_proj.bias', 'model.decoder.layers.14.fc1.weight', 'model.decoder.layers.7.fc1.bias', 'model.decoder.layers.20.self_attn.k_proj.weight', 'model.decoder.layers.15.self_attn_layer_norm.bias', 'model.decoder.layers.17.self_attn.k_proj.bias', 'model.decoder.layers.8.self_attn_layer_norm.weight', 'model.decoder.layers.5.fc1.bias', 'model.decoder.layers.11.fc1.bias', 'model.decoder.layers.18.self_attn.out_proj.weight', 'model.decoder.final_layer_norm.bias', 'model.decoder.layers.10.fc1.bias', 'model.decoder.layers.13.self_attn_layer_norm.bias', 'model.decoder.layers.15.fc1.weight', 'model.decoder.layers.18.self_attn_layer_norm.bias', 'model.decoder.layers.23.self_attn.v_proj.weight', 'model.decoder.layers.3.final_layer_norm.bias', 'model.decoder.layers.12.self_attn_layer_norm.bias', 'model.decoder.layers.15.self_attn.out_proj.bias', 'model.decoder.layers.0.self_attn.q_proj.weight', 'model.decoder.layers.11.final_layer_norm.weight', 'model.decoder.layers.19.fc2.weight', 'model.decoder.layers.9.self_attn.v_proj.weight', 'model.decoder.layers.21.self_attn.v_proj.weight', 'model.decoder.layers.29.self_attn.k_proj.weight', 'model.decoder.layers.13.self_attn.out_proj.weight', 'model.decoder.layers.12.final_layer_norm.weight', 'model.decoder.layers.26.self_attn.out_proj.bias', 'model.decoder.layers.9.fc2.weight', 'model.decoder.layers.14.self_attn_layer_norm.bias', 'model.decoder.layers.11.fc1.weight', 'model.decoder.layers.16.self_attn.q_proj.weight', 'model.decoder.layers.8.self_attn.k_proj.weight', 'model.decoder.layers.1.final_layer_norm.weight', 'model.decoder.layers.7.self_attn.k_proj.bias', 'model.decoder.layers.14.fc2.weight', 'model.decoder.layers.23.final_layer_norm.weight', 'model.decoder.layers.8.self_attn.q_proj.bias', 'model.decoder.layers.4.fc1.weight', 'model.decoder.layers.18.fc1.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\n",
    "    \n",
    "model = OPTForCausalLM.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\", \n",
    ")\n",
    "    \n",
    "model = PeftModel.from_pretrained(\n",
    "    model, \n",
    "    LORA_WEIGHTS, \n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    offload_folder=\"offload\", \n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed0f6660-5d7d-40dc-8951-1ebba1b09989",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"lingjoor/Mistral-7B-v1.1-Dolly-Longalpaca-Platypus-FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a047522-99ca-4069-80bf-7cfcafb8425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.save_pretrained(\"lingjoor/Mistral-7B-v1.1-Dolly-Longalpaca-Platypus-FT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf546861-8088-4c21-b63b-99719def942b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('3.10.0')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "8adbe73af6dcf57f041e980de1759080172e1f234c2c6e403df01ae2ead3fbed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
